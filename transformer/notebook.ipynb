{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a3f8fd-077e-4040-ae55-8e19ecee748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tokenizer.BPE import Tokenizer\n",
    "from utils.raw_data import load_wmt_chunk_df, get_wmt_df_len\n",
    "import numpy as np\n",
    "import math\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from model import Transformer\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.dataset import NeuralTranslationDataset\n",
    "\n",
    "# DEBUG\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba2ac7f-3113-4bcb-a5e9-9d35c9b1c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "tokenizer = Tokenizer(compute_vocab=False, \n",
    "                      max_vocab_size=37_005,\n",
    "                      corpus_source='wmt',\n",
    "                      vocab_dest_file=Path('./data/dest/wmt_37k_tokens.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b43cc4a-64da-4e7a-86d3-886500c34ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "data_test = NeuralTranslationDataset(subset='test')\n",
    "\n",
    "# dataloader\n",
    "loader = DataLoader(data_test,\n",
    "                    batch_size=3,\n",
    "                    shuffle=False,\n",
    "                    num_workers=4, \n",
    "                    pin_memory=True)\n",
    "\n",
    "# sample data\n",
    "for batch in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "951d7791-d161-4c96-be6d-eb49924298fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# model\n",
    "transformer = Transformer(N=3, \n",
    "                          L=64, \n",
    "                          d=512, \n",
    "                          h=8, \n",
    "                          d_ff=2048,\n",
    "                          n_vocab=len(tokenizer.token_vocab), \n",
    "                          padding_idx=tokenizer.token_vocab['<PAD>'], \n",
    "                          bos_idx=tokenizer.token_vocab['<BOS>'], \n",
    "                          dtype=torch.float, \n",
    "                          device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "811f9db9-8854-497f-87d2-2fcefd881964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 512])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer(**batch).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf99c8c-d5f9-4fdd-b151-c5ddf6e5f270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d15b6-b4dc-4dd3-bd99-49f7dece71b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo",
   "language": "python",
   "name": "bo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
